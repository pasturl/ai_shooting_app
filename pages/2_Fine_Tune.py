"""
Fine-Tuning Page for Flux Image Generator

This module provides a user interface for fine-tuning custom LoRA models using the Replicate API.
It includes comprehensive controls for dataset upload, training parameters, and model configuration.

Author: Your Name
Date: 2024
"""

import streamlit as st
import os
from typing import Optional, Dict, Any
import json
import replicate
from utils.aws import upload_to_s3, download_from_s3

# Constants
REPLICATE_API_TOKEN = os.getenv("REPLICATE_API_TOKEN")
DEFAULT_STEPS = 2000
DEFAULT_LORA_RANK = 32

def display_fine_tuning_tips():
    """Display comprehensive tips for successful LoRA fine-tuning."""
    st.sidebar.markdown("""
    # üìö Fine-Tuning Tips
    
    ## üìä Dataset Requirements
    - **Size**: 12-18 high-quality images
    - **Resolution**: 1024x1024 or larger
    - **Format**: File names must be captions (e.g., a_photo_of_TOK.png)
    
    ## üéØ Image Selection
    ### For Style LoRAs
    - Select images highlighting distinctive style features
    - Use varied subjects with consistent style
    - Avoid dataset domination by specific elements
    
    ### For Character LoRAs
    - Include different settings and expressions
    - Maintain consistent appearance (hair, age)
    - Limit hand-framing poses to prevent hallucinations
    
    ## ‚öôÔ∏è Training Parameters
    - Use generic proper names for trigger words
    - LoRA Rank: 16-32 (up to 64 for likeness)
    - Increase steps for weaker datasets
    - Dataset quality affects style flexibility
    
    ## üé® Inference Tips
    - Pair trigger words with gender terms
    - Adjust LoRA strength (0.8-0.95) for style control
    
    ## üìù Example Fine-Tunes
    - [Watercolor Style](https://replicate.com/lucataco/flux-watercolor)
    - [Pixar Cars Style](https://replicate.com/fofr/flux-pixar-cars)
    - [Vintage 2004](https://replicate.com/fofr/flux-2004)
    """)

def main():
    """Main function for the Fine-Tuning interface."""
    st.title("üé® Custom LoRA Fine-Tuning")
    st.markdown("""
    Create your own custom LoRA model by fine-tuning Flux with your dataset.
    Follow the guidelines for best results.
    """)
    
    # Display tips in sidebar
    display_fine_tuning_tips()
    
    # Main interface
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # Dataset upload section
        st.header("üì§ Dataset Upload")
        uploaded_file = st.file_uploader(
            "Upload your training images (ZIP/TAR)",
            type=["zip", "tar"],
            help="File names should be descriptive captions"
        )
        
        # Training parameters
        st.header("‚öôÔ∏è Training Configuration")
        trigger_word = st.text_input(
            "Trigger Word",
            help="A unique identifier for your model (e.g., 'TOK')"
        )
        
        steps = st.slider(
            "Training Steps",
            min_value=1000,
            max_value=3000,
            value=DEFAULT_STEPS,
            help="More steps can improve quality but increase training time"
        )
        
        lora_rank = st.slider(
            "LoRA Rank",
            min_value=8,
            max_value=64,
            value=DEFAULT_LORA_RANK,
            help="Higher rank can capture more detail but requires more memory"
        )
    
    with col2:
        # Model destination
        st.header("üéØ Model Destination")
        destination = st.text_input(
            "Replicate Model Location",
            help="Format: username/model-name"
        )
        
        # Advanced options
        with st.expander("üîß Advanced Options"):
            learning_rate = st.number_input(
                "Learning Rate",
                min_value=1e-6,
                max_value=1e-3,
                value=1e-4,
                format="%.6f"
            )
            
            batch_size = st.number_input(
                "Batch Size",
                min_value=1,
                max_value=8,
                value=4
            )
    
    # Training button
    if st.button("üöÄ Start Training", type="primary"):
        if not all([uploaded_file, trigger_word, destination]):
            st.error("Please fill in all required fields")
            return
            
        try:
            # Training logic here
            with st.spinner("Training in progress..."):
                # Implementation of training process
                pass
            
            st.success(f"Training completed! Your model will be available at: {destination}")
            
        except Exception as e:
            st.error(f"Training failed: {str(e)}")

if __name__ == "__main__":
    main()